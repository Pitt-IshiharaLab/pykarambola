{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Processing with joblib\n",
    "\n",
    "This notebook demonstrates how to use `joblib.Parallel` to compute Minkowski functionals\n",
    "on many meshes in parallel using pykarambola.\n",
    "\n",
    "`joblib` is popular in the scientific Python ecosystem (used internally by scikit-learn)\n",
    "and offers a cleaner API than raw `multiprocessing`, with built-in progress reporting\n",
    "and smart memory handling for numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "import pykarambola"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrays_from_triangulation(tri):\n",
    "    \"\"\"Extract vertex/face numpy arrays from a Triangulation object.\"\"\"\n",
    "    nv, nt = tri.n_vertices(), tri.n_triangles()\n",
    "    verts = np.array([tri.get_pos_of_vertex(i) for i in range(nv)], dtype=np.float64)\n",
    "    faces = np.array(\n",
    "        [[tri.ith_vertex_of_triangle(j, i) for i in range(3)] for j in range(nt)],\n",
    "        dtype=np.int64,\n",
    "    )\n",
    "    return verts, faces\n",
    "\n",
    "\n",
    "def make_box(a, b, c):\n",
    "    \"\"\"Return (verts, faces) for an axis-aligned box of size a x b x c centred at origin.\"\"\"\n",
    "    ha, hb, hc = a / 2, b / 2, c / 2\n",
    "    verts = np.array([\n",
    "        [-ha, -hb, -hc], [ ha, -hb, -hc], [ ha,  hb, -hc], [-ha,  hb, -hc],\n",
    "        [-ha, -hb,  hc], [ ha, -hb,  hc], [ ha,  hb,  hc], [-ha,  hb,  hc],\n",
    "    ], dtype=np.float64)\n",
    "    faces = np.array([\n",
    "        [0, 3, 2], [0, 2, 1],\n",
    "        [4, 5, 6], [4, 6, 7],\n",
    "        [0, 1, 5], [0, 5, 4],\n",
    "        [2, 3, 7], [2, 7, 6],\n",
    "        [0, 4, 7], [0, 7, 3],\n",
    "        [1, 2, 6], [1, 6, 5],\n",
    "    ], dtype=np.int64)\n",
    "    return verts, faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate synthetic meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "N_MESHES = 200\n",
    "meshes = [make_box(*rng.uniform(1, 10, size=3)) for _ in range(N_MESHES)]\n",
    "\n",
    "print(f\"Generated {N_MESHES} random boxes\")\n",
    "print(f\"Available CPU cores: {cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sequential baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.perf_counter()\n",
    "results_seq = [\n",
    "    pykarambola.minkowski_functionals(v, f) for v, f in meshes\n",
    "]\n",
    "dt_seq = time.perf_counter() - t0\n",
    "\n",
    "print(f\"Sequential: {dt_seq:.3f}s for {N_MESHES} meshes ({dt_seq/N_MESHES*1000:.1f} ms/mesh)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parallel with joblib\n",
    "\n",
    "The `delayed` wrapper lets you write natural function calls. `n_jobs=-1` uses all cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.perf_counter()\n",
    "results_par = Parallel(n_jobs=-1)(\n",
    "    delayed(pykarambola.minkowski_functionals)(v, f) for v, f in meshes\n",
    ")\n",
    "dt_par = time.perf_counter() - t0\n",
    "\n",
    "print(f\"Parallel:   {dt_par:.3f}s for {N_MESHES} meshes ({dt_par/N_MESHES*1000:.1f} ms/mesh)\")\n",
    "print(f\"Speedup:    {dt_seq/dt_par:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (r_seq, r_par) in enumerate(zip(results_seq, results_par)):\n",
    "    for key in r_seq:\n",
    "        assert np.allclose(r_seq[key], r_par[key]), f\"Mismatch at mesh {i}, key {key}\"\n",
    "\n",
    "print(\"All results match between sequential and parallel execution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verbose mode and progress tracking\n",
    "\n",
    "One of joblib's advantages: set `verbose=10` to see progress during long-running batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_verbose = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(pykarambola.minkowski_functionals)(v, f) for v, f in meshes[:20]\n",
    ")\n",
    "\n",
    "print(f\"\\nProcessed {len(results_verbose)} meshes with verbose output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Controlling the number of workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_jobs in [1, 2, 4, -1]:\n",
    "    t0 = time.perf_counter()\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(pykarambola.minkowski_functionals)(v, f) for v, f in meshes\n",
    "    )\n",
    "    dt = time.perf_counter() - t0\n",
    "    label = f\"{n_jobs} jobs\" if n_jobs > 0 else f\"{cpu_count()} jobs (all cores)\"\n",
    "    print(f\"  {label:<25s}: {dt:.3f}s  (speedup {dt_seq/dt:.2f}x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Passing keyword arguments with `delayed`\n",
    "\n",
    "Unlike `ProcessPoolExecutor.map`, joblib's `delayed` supports keyword arguments naturally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only compute volume and surface area, with centroid centering\n",
    "results_subset = Parallel(n_jobs=-1)(\n",
    "    delayed(pykarambola.minkowski_functionals)(\n",
    "        v, f, compute=['w000', 'w100'], center='centroid',\n",
    "    )\n",
    "    for v, f in meshes\n",
    ")\n",
    "\n",
    "print(f\"First 5 volumes:  {[r['w000'] for r in results_subset[:5]]}\")\n",
    "print(f\"First 5 areas:    {[round(r['w100'], 2) for r in results_subset[:5]]}\")\n",
    "print(f\"Keys per result:  {sorted(results_subset[0].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Processing mesh files in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_from_poly_file(filepath):\n",
    "    \"\"\"Load a .poly file and compute Minkowski functionals.\"\"\"\n",
    "    tri = pykarambola.parse_poly_file(str(filepath))\n",
    "    verts, faces = arrays_from_triangulation(tri)\n",
    "    return {\n",
    "        'file': filepath.name,\n",
    "        'n_verts': tri.n_vertices(),\n",
    "        'n_faces': tri.n_triangles(),\n",
    "        'functionals': pykarambola.minkowski_functionals(verts, faces),\n",
    "    }\n",
    "\n",
    "\n",
    "poly_files = sorted(Path('../test_suite/inputs').glob('*.poly'))\n",
    "print(f\"Found {len(poly_files)} .poly files\")\n",
    "\n",
    "file_results = Parallel(n_jobs=-1)(\n",
    "    delayed(compute_from_poly_file)(p) for p in poly_files\n",
    ")\n",
    "\n",
    "for r in file_results:\n",
    "    vol = r['functionals'].get('w000', float('nan'))\n",
    "    print(f\"  {r['file']:<50s}  V={r['n_verts']:>4d}  F={r['n_faces']:>4d}  vol={vol:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 9. Writing results to CSV\n\nAll results are collected in the main process before writing, so a plain pandas `DataFrame` is safe \u2014 no locking needed.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import pandas as pd\n\nrows = [\n    {\"file\": r[\"file\"], \"n_verts\": r[\"n_verts\"], \"n_faces\": r[\"n_faces\"], **r[\"functionals\"]}\n    for r in file_results\n]\ndf = pd.DataFrame(rows)\ndf.to_csv(\"results.csv\", index=False)\nprint(df.to_string())",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10. Processing label images in parallel"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic label images: spheres of varying radii\n",
    "shape = (64, 64, 64)\n",
    "z, y, x = np.mgrid[:shape[0], :shape[1], :shape[2]]\n",
    "center = np.array(shape) / 2\n",
    "\n",
    "images = []\n",
    "radii = [10, 15, 20, 25]\n",
    "for r in radii:\n",
    "    dist = np.sqrt((x - center[2])**2 + (y - center[1])**2 + (z - center[0])**2)\n",
    "    img = np.zeros(shape, dtype=int)\n",
    "    img[dist <= r] = 1\n",
    "    images.append(img)\n",
    "\n",
    "print(f\"Processing {len(images)} label images...\")\n",
    "\n",
    "img_results = Parallel(n_jobs=-1)(\n",
    "    delayed(pykarambola.minkowski_functionals_from_label_image)(\n",
    "        img, center='centroid',\n",
    "    )\n",
    "    for img in images\n",
    ")\n",
    "\n",
    "for res, radius in zip(img_results, radii):\n",
    "    vol = res[1]['w000']\n",
    "    expected = 4/3 * np.pi * radius**3\n",
    "    print(f\"  radius={radius:>2d}  vol={vol:>10.1f}  expected={expected:>10.1f}  err={abs(vol-expected)/expected:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Choosing a backend\n",
    "\n",
    "joblib supports multiple backends:\n",
    "- `\"loky\"` (default): robust process-based parallelism, handles numpy well\n",
    "- `\"multiprocessing\"`: uses stdlib `multiprocessing`\n",
    "- `\"threading\"`: uses threads \u2014 no speedup for CPU-bound work (GIL), but useful for I/O-bound tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for backend in ['loky', 'threading']:\n",
    "    t0 = time.perf_counter()\n",
    "    results = Parallel(n_jobs=-1, backend=backend)(\n",
    "        delayed(pykarambola.minkowski_functionals)(v, f) for v, f in meshes\n",
    "    )\n",
    "    dt = time.perf_counter() - t0\n",
    "    print(f\"  {backend:<15s}: {dt:.3f}s  (speedup {dt_seq/dt:.2f}x)\")\n",
    "\n",
    "print(\"\\nNote: 'threading' shows no speedup due to Python's GIL. Use 'loky' (default) for CPU-bound work.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips\n",
    "\n",
    "- **`n_jobs=-1`**: use all cores. `-2` = all but one core (leaves one free for other tasks).\n",
    "- **`delayed`**: wraps any callable with natural `f(args, kwargs)` syntax \u2014 no tuple packing needed.\n",
    "- **`verbose`**: set to 1-10 for progress output during long batches.\n",
    "- **`backend=\"loky\"`** (default): best for CPU-bound numpy work. Handles numpy memory efficiently.\n",
    "- **Memory**: `joblib` uses memory-mapped numpy arrays to reduce serialization overhead\n",
    "  when passing large arrays between processes.\n",
    "- **Install**: `pip install joblib` (often already installed as a dependency of scikit-learn)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}